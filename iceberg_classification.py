# -*- coding: utf-8 -*-
"""Iceberg Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JzkOIu0vQ6WnutzHeDdwq4iE2y5nCHuV

# Introduction
- 멀리 있는 물체가 빙하 또는 선박인지 확인하는 모델을 만들어 보자.
"""

# Commented out IPython magic to ensure Python compatibility.
# import module
import numpy as np
import pandas as pd
from subprocess import check_output
from sklearn.model_selection import train_test_split, StratifiedKFold
from os.path import join as opj
from matplotlib import pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import pylab
import seaborn as sns
plt.rcParams['figure.figsize'] = 10, 10
# %matplotlib inline

"""Loading Data"""

train = pd.read_json('/content/drive/My Drive/Kaggle/Iceberg Classification/train.json')
test = pd.read_json('/content/drive/My Drive/Kaggle/Iceberg Classification/test.json')

"""#Data at one sight

데이터에 대한 설명이 처음에 주어졌다. 
- id : id of the image
- band_1, band_2 : the flatted image data. 75*75 pixel values. Band1, Band2 는 radar backscatter로 특징지어진 신호다. 여기에 두 가지 value가 있다. HH(transmit/recieve horizontally), HV(transmit horizontally and receive vertically).
- inc_angle : the incidence angle of which the image was taken. missing data는 na로 처리되었다.
- is_iceberg : the target variable, set to 1 if it is and iceberg, and 0 if it is a ship.
"""

train.head()

len(train)

test.head()

f, ax = plt.subplots(1,1,figsize=(15,6))
sns.barplot(x=['not iceberg', 'iceberg'], y=train.groupby(['is_iceberg'], as_index=False).count()['id'])
plt.show()

"""- 데이터가 balanced하다

# Plotting some images
- It's good to plot some images before we do. That way, we can get some sense of what we're looking at.
"""

img1 = np.array(train.iloc[0]['band_1']).reshape((75,75))
plt.subplot(1,3,1)
plt.imshow(img1)

plt.subplot(1,3,2)
img2 = np.array(train.iloc[0]['band_2']).reshape((75,75))
plt.imshow(img2)
plt.subplot(1,3,3)
plt.imshow(img1 + img2)

#training data
X_band_1 = np.array([np.array(band).astype(np.float32).reshape(75,75) for band in train['band_1']])
X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train["band_2"]])
X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)

y_train = train['is_iceberg']

#test data
X_band_test_1 = np.array([np.array(band).astype(np.float32).reshape(75,75) for band in test['band_1']])
X_band_test_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_2']])
X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]
                          , X_band_test_2[:, :, :, np.newaxis]
                         , ((X_band_test_1+X_band_test_2)/2)[:, :, :, np.newaxis]], axis=-1)

train['inc_angle'] = pd.to_numeric(train['inc_angle'], errors='coerce')
test['inc_angle'] = pd.to_numeric(test['inc_angle'], errors='coerce')

train['inc_angle'] = train['inc_angle'].fillna(method='pad') # 결측값 주변값으로 채우기
test['inc_angle'] = test['inc_angle'].fillna(method='pad')

X_train_angle = train['inc_angle']
x_test_angle = test['inc_angle']

X_train[0]

"""Let's look at more image

# Data Preprocessing
"""

from sklearn.model_selection import train_test_split

X_train, X_valid, X_train_angle, X_valid_angle, y_train, y_valid = train_test_split(X_train,
                                    X_train_angle, y_train, random_state=42, train_size=0.8)

"""## Building Model"""

#import module
import keras
from keras import optimizers
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential, Model
from keras.layers import Layer, Conv2D, MaxPooling2D,GlobalMaxPooling2D, Dense, Dropout, Input, Flatten, Activation
from keras.layers.normalization import BatchNormalization
from keras.layers.merge import Concatenate
from keras import initializers
from keras.layers.advanced_activations import LeakyReLU, PReLU
from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping,ReduceLROnPlateau
from keras.optimizers import Adam
from keras.datasets import cifar10
from keras.applications.inception_v3 import InceptionV3
from keras.applications.vgg16 import VGG16
from keras.applications.xception import Xception
from keras.applications.mobilenet import MobileNet
from keras.applications.vgg19 import VGG19

model = keras.models.Sequential()
#conv layer 1
model.add(Conv2D(64, kernel_size=(3,3), activation='relu', input_shape=(75,75,3)))
model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))
model.add(Dropout(0.2))

#conv layer 2
model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))
model.add(Dropout(0.2))

#Conv layer 3
model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))
model.add(Dropout(0.2))

#Conv layer 4
model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))
model.add(Dropout(0.2))

#You must flatten the data for the dense layer
model.add(Flatten())

#Dense layer1
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.2))

#Dense layer 2
model.add(Dense(256))
model.add(Activation('relu'))
model.add(Dropout(0.2))

model.add(Dense(1))
model.add(Activation('sigmoid'))

optim = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0)
model.compile(loss='binary_crossentropy',
              optimizer=optim,
              metrics=['accuracy'])

model.summary()

def get_callbacks(filepath, patience=2):
  es = EarlyStopping('val_loss', patience=10, mode='min')
  msave = ModelCheckpoint(filepath, save_best_only=True)
  return [es, msave]

file_path = ".model_weights.hdf5"
callbacks = get_callbacks(filepath=file_path, patience=5)

"""## Training Model"""

import os
model.fit(X_train, y_train,
          batch_size=32,
          epochs=50,
          verbose=1,
          validation_data=(X_valid, y_valid),
          callbacks=callbacks)

"""# Evaluate model"""

model.load_weights(filepath=file_path)
score = model.evaluate(X_valid, y_valid, verbose=1)
print('Test loss', score[0])
print('Test accuracy', score[1])

"""- 84.74%의 정확도 0.30의 loss를 얻었다."""

predict_test = model.predict(X_test)
predict_test

submission = pd.DataFrame()
submission['id'] = test['id']
submission['is_iceberg']=predict_test.reshape((predict_test.shape[0]))
submission.to_csv('sub.csv', index=False)